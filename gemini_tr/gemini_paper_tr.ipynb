{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimin\\anaconda3\\envs\\Openai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    " \n",
    "import google.generativeai as genai\n",
    " \n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from config import Config\n",
    " \n",
    "# 서식이 지정된 Markdown 텍스트를 표시하는 함수\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    " \n",
    "# 제미나이 API 키 설정\n",
    "genai.configure(api_key=Config.GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0827\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')  # 텍스트 전용 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'Attention paper summary' as: https://generativelanguage.googleapis.com/v1beta/files/1bivcl86olck\n"
     ]
    }
   ],
   "source": [
    "# Path to the PDF file in the 'files' folder\n",
    "file_path = \"C:/Users/kimin/cv-project/my-cv-project/gemini_tr/2017_NIPS_Attention Is All You Need.pdf\"\n",
    "\n",
    "sample_file = genai.upload_file(path=file_path, display_name=\"Attention paper summary\")\n",
    "\n",
    "# Confirm upload\n",
    "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 이 논문의 주요 내용은 다음과 같습니다.\n",
      "\n",
      "* 기존의 순서형 인코더-디코더 구조에서 벗어나, self-attention만을 사용하는 Transformer라는 새로운 네트워크 구조를 제안합니다.\n",
      "* Transformer는 병렬 처리에 유리하고, 학습 속도가 빠르며, 번역 품질도 우수합니다.\n",
      "* Transformer는 WMT 2014 영어-독일어 번역 작업에서 28.4 BLEU, WMT 2014 영어-프랑스어 번역 작업에서 41.0 BLEU를 달성하여, 기존의 최고 기록을 갱신했습니다.\n",
      "\n",
      "이 논문의 주요 기여는 self-attention만을 사용하는 Transformer라는 새로운 네트워크 구조를 제안한 것입니다. Transformer는 기존의 순서형 인코더-디코더 구조에 비해 병렬 처리에 유리하고, 학습 속도가 빠르며, 번역 품질도 우수합니다. Transformer는 WMT 2014 영어-독일어 번역 작업과 WMT 2014 영어-프랑스어 번역 작업에서 모두 기존의 최고 기록을 갱신하여, 기계 번역 분야의 새로운 지평을 열었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Generate content using the uploaded document\n",
    "response = model.generate_content([sample_file, \"이 논문의 main contribution은 뭐야??\"])\n",
    "\n",
    "# Print the generated content\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
