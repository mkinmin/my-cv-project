{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimin\\anaconda3\\envs\\Openai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    " \n",
    "import google.generativeai as genai\n",
    " \n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from config import Config\n",
    " \n",
    "# 서식이 지정된 Markdown 텍스트를 표시하는 함수\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    " \n",
    "# 제미나이 API 키 설정\n",
    "genai.configure(api_key=Config.GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0827\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')  # 텍스트 전용 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'Attention paper summary' as: https://generativelanguage.googleapis.com/v1beta/files/zb18ymy8j04c\n"
     ]
    }
   ],
   "source": [
    "# '파일' 폴더에 있는 PDF 파일 경로\n",
    "file_path = \"C:/Users/kimin/cv-project/my-cv-project/gemini_tr/paper/시계열 데이터 분석을 위한 SAR영상 비교기법 연구.pdf\"\n",
    "\n",
    "sample_file = genai.upload_file(path=file_path, display_name=\"Attention paper summary\")\n",
    "\n",
    "# 업로드 확인\n",
    "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.67.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-aiplatform) (2.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-aiplatform) (5.28.1)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.0.6-cp39-cp39-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-aiplatform) (2.9.1)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-storage) (2.32.3)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Downloading google_crc32c-1.6.0-cp39-cp39-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n",
      "Collecting numpy<3,>=1.14 (from shapely<3.0.0dev->google-cloud-aiplatform)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kimin\\anaconda3\\envs\\openai\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Downloading google_cloud_aiplatform-1.67.0-py2.py3-none-any.whl (5.2 MB)\n",
      "   ---------------------------------------- 0.0/5.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.2/5.2 MB 31.7 MB/s eta 0:00:00\n",
      "Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl (239 kB)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
      "Downloading google_crc32c-1.6.0-cp39-cp39-win_amd64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Downloading shapely-2.0.6-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 73.8 MB/s eta 0:00:00\n",
      "Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Installing collected packages: numpy, google-crc32c, docstring-parser, shapely, google-resumable-media, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "Successfully installed docstring-parser-0.16 google-cloud-aiplatform-1.67.0 google-cloud-bigquery-3.25.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.5 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 grpc-google-iam-v1-0.13.1 numpy-2.0.2 shapely-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from PyPDF2 import PdfReader\n",
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> The title of the paper is:\n",
       "> \n",
       "> **시계열 데이터 분석을 위한 SAR영상 비교기법 연구** \n",
       "> \n",
       "> This translates to:\n",
       "> \n",
       "> **A Study on SAR Image Comparison Techniques for Time Series Data Analysis** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> ## 항공우주시스템공학회 2024년도 춘계학술대회 논문 요약: SAR 영상 비교 기법 연구\n",
       "> \n",
       "> **1. 서론**\n",
       "> \n",
       "> 최근 이동 플랫폼에 탑재된 SAR(합성개구면레이다) 기술 발전과 보편화로 다양한 SAR 위성이 개발되고 있습니다. 특히 수십 개의 소형 SAR 위성을 동시 운용하여 동일 지역을 짧은 주기로 반복 측정하는 추세가 확산되고 있습니다. [1] \n",
       "> \n",
       "> 동일 지역을 반복 측정하여 위상 변화, 후방 산란 계수 변화를 분석하면 변화 탐지를 통해 다양한 정보를 얻을 수 있습니다. 정확한 변화 탐지를 위해서는 SAR 영상 측정 당시 비나 구름 등 외부 환경 요인과 실제 지표면 변화를 구별해야 합니다. 또한, 지속적인 반복 측정으로 누적되는 시계열 데이터를 일관되고 정량적인 기법으로 분석해야 합니다. \n",
       "> \n",
       "> 본 논문에서는 영상 비교 기법으로 잘 알려진 SSIM(구조적 유사성 지표)과 GLCM(회색조 공동 발생 행렬)을 이용하여 영상 변화에 따른 분석 결과를 확인합니다.\n",
       "> \n",
       "> **2. 본론**\n",
       "> \n",
       "> 정확한 SAR 영상 비교를 위해 영상 정합을 수행합니다. 먼저 영상에서 특징점을 선별하고 KAZE 알고리즘으로 두 영상 특징점 근방의 유사도를 유클리디안 거리를 이용하여 구합니다. SAR 영상의 변화 탐지를 위해서는 두 영상의 비변화 화소들이 완벽하게 일치해야 하므로, 특징점을 매칭할 때 이상치를 제거해야 합니다. 따라서 노이즈 및 이상치 제거에 효율적인 RANSAC(랜덤 샘플 컨센서스) 알고리즘을 사용하여 두 영상의 특징점 이상치를 제거합니다. 이는 두 영상의 세기에 차이가 있어도 이상치를 제거하여 정확한 정합을 가능하게 합니다. SLC(단일 룩 복소수) 데이터를 dB 값으로 변환할 때 필터를 이용하여 추가적으로 두 영상의 노이즈를 제거합니다. \n",
       "> \n",
       "> SAR 영상 비교 기법으로는 흑백 영상을 동시 발생 행렬로 변환하여 ASM, Contrast, Homogeneity 등을 분석할 수 있는 GLCM과 두 영상의 유사도를 나타내는 SSIM을 사용합니다.\n",
       "> \n",
       "> 그림 1은 SAR 영상의 비교, 분석을 위해 원본 영상에 임의의 speckle 잡음 변화를 주어 GLCM 분석 결과를 비교한 그림입니다. 그림 1(a)는 원본 영상이며, 그림 1(b)는 외부 환경 등에 의한 영상 품질 변화를 인가하기 위해 speckle 잡음을 추가한 영상입니다. GLCM 배열이 대각 행렬에 가까이 분포할수록 영상의 픽셀 변화가 적고, 멀리 분포할수록 픽셀 변화가 큰 영상과 같습니다. 그림 1(b)는 그림 1(a)에 비해 GLCM 결과가 대각 행렬에서 멀리 분포하는 것을 볼 수 있습니다.\n",
       "> \n",
       "> 이러한 결과들을 정량적으로 비교, 분석하기 위해 ASM, contrast, Homogeneity 등을 추출한 결과는 표 1과 같습니다. 해당 결과는 지표면의 종류, 외부 환경 변화, 잡음 패턴의 세기 등에 의해 달라집니다. 예를 들어 바다와 같이 변화가 적은 지역은 외부 환경 요인에 의해 contrast가 증가하며, 잡음 패턴의 세기가 작을수록 픽셀의 대비가 작아져 contrast가 감소하게 됩니다.\n",
       "> \n",
       "> 그림 2는 영상에 인가한 speckle 잡음의 분산을 0.1에서 0.5까지 증가시키며 영상 특성의 변화를 분석한 예입니다. 잡음의 분산이 커질수록 잡음으로 인해 명암도가 불균일해지며, 명암도 차이가 커 contrast, variance가 증가하는 것을 볼 수 있습니다. 또한 원본 영상과 비교하였을 때 SSIM은 잡음의 분산이 클수록 감소했습니다.\n",
       "> \n",
       "> **3. 결론**\n",
       "> \n",
       "> 본 논문에서는 SAR 영상 비교를 위한 영상 정합 및 비교 기법 연구를 수행했습니다. 영상에 임의의 speckle 잡음을 인가하며 분석 결과의 경향을 파악했습니다. 이러한 결과는 시계열 데이터 분석 등에 활용될 수 있을 것으로 기대됩니다.\n",
       "> \n",
       "> **후기**\n",
       "> \n",
       "> 이 논문은 2023년 정부(방위사업청)의 재원으로 국방과학연구소의 지원을 받아 수행된 연구입니다. (UG223018YD) \n",
       "> \n",
       "> **참고 문헌**\n",
       "> \n",
       "> [1] K. Ouchi, “Recent trend and advance of synthetic aperture radar with selected topics“, Remote Sensing, pp. 716-807, 2013.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> ## 항공우주시스템공학회 2024년도 춘계학술대회 논문 초록 번역\n",
       "> \n",
       "> **본 논문에서는 동일 지역을 반복 측정한 SAR(합성개구면레이다) 영상을 비교하는 기법에 대한 연구 결과를 설명합니다.** 먼저 동일 지역의 SAR 영상을 정합 알고리즘을 이용하여 영상 좌표를 일치시키는 방법에 대해 설명합니다. 그리고 SSIM(구조적 유사성 지수 측정), GLCM(회색 수준 공동 발생 행렬) 등의 영상 비교 기법으로 영상을 비교하여 SAR 영상의 변화, 차이의 정도를 확인합니다.\n",
       "> \n",
       "> **주요 키워드**: 합성개구면레이다(SAR), SSIM, GLCM\n",
       "> \n",
       "> **요약:**\n",
       "> \n",
       "> * **SAR 영상의 변화 탐지를 위해서는 정확한 영상 정합이 필수적입니다.** 본 논문에서는 KAZE 알고리즘과 RANSAC 알고리즘을 사용하여 영상 정합을 수행하고, 노이즈 및 이상치를 제거하는 방법을 제시합니다.\n",
       "> * **SAR 영상 비교 기법으로 GLCM과 SSIM을 사용합니다.** GLCM은 흑백 영상을 동시 발생 행렬로 변환하여 ASM, Contrast, Homogeneity 등을 분석하는 방법이고, SSIM은 두 영상의 유사도를 나타내는 지표입니다.\n",
       "> * **임의의 speckle 잡음을 인가하여 GLCM 분석 결과를 비교합니다.** 잡음의 분산이 클수록 영상의 명암도 차이가 커지고, SSIM 값은 감소하는 경향을 확인합니다.\n",
       "> * **본 연구 결과는 시계열 데이터 분석 등에 활용될 수 있을 것으로 기대됩니다.**\n",
       "> \n",
       "> **참고**:\n",
       "> \n",
       "> * 본 논문은 2023년 정부(방위사업청)의 재원으로 국방과학연구소의 지원을 받아 수행된 연구입니다.\n",
       "> \n",
       "> **이 초록은 논문의 주요 내용을 간략하게 요약한 것입니다. 자세한 내용은 논문을 참조해 주시기 바랍니다.**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> ## 본문의 주요 내용 한국어 번역:\n",
       "> \n",
       "> 이 논문은 동일 지역을 반복 측정한 SAR(Synthetic Aperture Radar) 영상을 비교하는 기법에 대한 연구 결과를 설명합니다. \n",
       "> \n",
       "> **핵심 내용:**\n",
       "> \n",
       "> * **SAR 영상 정합:** 동일 지역의 SAR 영상을 정합 알고리즘을 이용하여 영상 좌표를 일치시키는 방법을 설명합니다. \n",
       "> * **영상 비교 기법:** SSIM(Structural Similarity index Measure)과 GLCM(Gray-Level Co-occurrence Matrix) 등의 영상 비교 기법을 사용하여 SAR 영상의 변화와 차이를 분석합니다. \n",
       "> * **GLCM 분석:** GLCM을 이용하여 외부 환경 변화, 잡음 등에 의한 SAR 영상의 변화를 분석하고, 특징적인 패턴을 확인합니다. \n",
       "> * **SSIM 분석:** SSIM을 통해 원본 영상과 잡음이 추가된 영상의 유사도를 측정하고, 잡음의 영향을 분석합니다. \n",
       "> * **실험 결과:** 임의의 speckle 잡음을 추가하여 영상 특성 변화를 분석하고, 잡음 분산에 따른 SSIM 및 GLCM 결과를 제시합니다.\n",
       "> \n",
       "> **결론:**\n",
       "> \n",
       "> * SAR 영상 비교를 위한 영상 정합 및 비교 기법 연구를 수행하여, 잡음 등 외부 요인에 의한 영상 변화를 정량적으로 분석하는 방법을 제시합니다. \n",
       "> * 연구 결과는 시계열 데이터 분석 등에 활용될 수 있을 것으로 기대됩니다. \n",
       "> \n",
       "> **추가:**\n",
       "> \n",
       "> * 본 연구는 국방과학연구소의 지원을 받아 수행되었습니다. \n",
       "> \n",
       "> **이 논문은 SAR 영상을 정확하게 비교하고 분석하는 방법을 제시하여, SAR 데이터를 활용한 다양한 분야에서 활용될 수 있는 가능성을 보여줍니다.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown content saved to translated_result.txt\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일에서 텍스트 추출\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        reader = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# 제미나이 API를 이용하여 텍스트 번역\n",
    "def find_title(text):\n",
    "    prompt = f\"find the title of this paper: {text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def summarize_paper(text):\n",
    "    prompt = f\"Summarize the following text into Korean: {text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def translate_abstract(text):\n",
    "    prompt = f\"Translate the abstract in the following text in Korean: {text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def translate_contribution(text):\n",
    "    prompt = f\"Translate the main contribution of the following text in Korean: {text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def save_to_markdown_file(title,summarized_text, abstract, main_contribution, file_name=\"translated_result.txt\"):\n",
    "    # text형식으로 만들기\n",
    "    text_content = f\"{title}\\n\\n{summarized_text}\\n\\n{abstract}\\n\\n{main_contribution}\"\n",
    "    \n",
    "    # Write to a text file\n",
    "    with open(file_name, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text_content)\n",
    "    \n",
    "    print(f\"Markdown content saved to {file_name}\")\n",
    "\n",
    "# PDF 파일에서 텍스트를 추출하고 번역\n",
    "pdf_text = extract_text_from_pdf(file_path)\n",
    "Title = find_title(pdf_text)\n",
    "Summarized_text = summarize_paper(pdf_text)\n",
    "Abstract = translate_abstract(pdf_text)\n",
    "Main_contribution = translate_contribution(pdf_text)\n",
    "\n",
    "# 번역된 결과를 Markdown 형식으로 출력\n",
    "display(to_markdown(Title))\n",
    "display(to_markdown(Summarized_text))\n",
    "display(to_markdown(Abstract))\n",
    "display(to_markdown(Main_contribution))\n",
    "\n",
    "# 결과물을 .txt 파일에 저장\n",
    "save_to_markdown_file(Title,Summarized_text, Abstract, Main_contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 이 논문의 주요 내용은 다음과 같습니다.\n",
      "\n",
      "* 기존의 순서형 인코더-디코더 구조에서 벗어나, self-attention만을 사용하는 Transformer라는 새로운 네트워크 구조를 제안합니다.\n",
      "* Transformer는 병렬 처리에 유리하고, 학습 속도가 빠르며, 번역 품질도 우수합니다.\n",
      "* Transformer는 WMT 2014 영어-독일어 번역 작업에서 28.4 BLEU, WMT 2014 영어-프랑스어 번역 작업에서 41.0 BLEU를 달성하여, 기존의 최고 기록을 갱신했습니다.\n",
      "\n",
      "이 논문의 주요 기여는 self-attention만을 사용하는 Transformer라는 새로운 네트워크 구조를 제안한 것입니다. Transformer는 기존의 순서형 인코더-디코더 구조에 비해 병렬 처리에 유리하고, 학습 속도가 빠르며, 번역 품질도 우수합니다. Transformer는 WMT 2014 영어-독일어 번역 작업과 WMT 2014 영어-프랑스어 번역 작업에서 모두 기존의 최고 기록을 갱신하여, 기계 번역 분야의 새로운 지평을 열었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Generate content using the uploaded document\n",
    "response = model.generate_content([sample_file, \"이 논문의 main contribution은 뭐야??\"])\n",
    "\n",
    "# Print the generated content\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
